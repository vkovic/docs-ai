{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:57:01.751206Z",
     "start_time": "2024-11-24T21:57:01.748115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# def run_sql_command():\n",
    "#     session = SessionFactory()\n",
    "#     try:\n",
    "#         session.execute(text('CREATE EXTENSION IF NOT EXISTS vector'))\n",
    "#         session.commit()\n",
    "#     finally:\n",
    "#         session.close()"
   ],
   "id": "210c90ac585103b3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:57:03.397416Z",
     "start_time": "2024-11-24T21:57:03.293177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Open a connection to the database\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "DATABASE_URL = \"postgresql+psycopg2://user:password@db/vectordb\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "SessionFactory = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "\n",
    "session = SessionFactory()"
   ],
   "id": "6c9c845c8f475a30",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:57:04.960396Z",
     "start_time": "2024-11-24T21:57:04.833583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a table with a vector column\n",
    "\n",
    "from sqlalchemy import Integer, String\n",
    "from sqlalchemy.orm import mapped_column, declarative_base\n",
    "from pgvector.sqlalchemy import Vector\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Item(Base):\n",
    "    __tablename__ = 'embeddings'\n",
    "    id = mapped_column(Integer, primary_key=True)\n",
    "    embedding = mapped_column(Vector(768))\n",
    "    text = mapped_column(String)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<Item(text={self.text[:30]}...)>\""
   ],
   "id": "77180837e17d8842",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:57:08.790300Z",
     "start_time": "2024-11-24T21:57:06.691968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create example documents for embedding\n",
    "\n",
    "from ollama import Client\n",
    "\n",
    "client = Client(host='ollama:11434')\n",
    "\n",
    "documentation = [\n",
    "    {\n",
    "        \"title\": \"API Documentation - User Service\",\n",
    "        \"content\": \"The User Service API allows CRUD operations on user data. The base URL is '/api/users'. GET /api/users retrieves all users. POST /api/users creates a new user.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Architecture Guidelines - Microservices\",\n",
    "        \"content\": \"Our architecture is based on microservices. Each service is independent and communicates with others via REST APIs. Services are deployed in Docker containers and managed via Kubernetes.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Code Standards\",\n",
    "        \"content\": \"Our codebase follows PSR-12 for PHP code. All PHP classes should have docblocks, and methods should be named in camelCase. JavaScript follows the Airbnb style guide.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"CI/CD Pipeline\",\n",
    "        \"content\": \"We use GitLab CI for continuous integration and deployment. The pipeline includes stages for linting, testing, building, and deployment. Automated tests are required before deployment.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "emb_data = []\n",
    "for doc in documentation:\n",
    "    vector = client.embeddings(model='nomic-embed-text', prompt=doc['content'])\n",
    "    embedding = vector['embedding']\n",
    "    content = doc['content']\n",
    "    emb_data.append((embedding, content))"
   ],
   "id": "d93887c6cdaaf15b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:57:10.975033Z",
     "start_time": "2024-11-24T21:57:10.952162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Write vector data into the database\n",
    "\n",
    "for embedding, content in emb_data:\n",
    "    item = Item(embedding=embedding, text=content)\n",
    "    session.add(item)\n",
    "    \n",
    "session.commit()\n",
    "session.close()"
   ],
   "id": "1abe513fcf08d420",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T21:57:13.075960Z",
     "start_time": "2024-11-24T21:57:12.998245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a question (embeddings)\n",
    "\n",
    "question = \"How do we deploy services in our architecture?\"\n",
    "question_vector = client.embeddings(model='nomic-embed-text', prompt=question)['embedding']"
   ],
   "id": "cdf835c58f420fad",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T22:09:36.840337Z",
     "start_time": "2024-11-24T22:09:36.830975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Query the database for similar documents\n",
    "\n",
    "results = (\n",
    "    session.query(\n",
    "        Item,\n",
    "        (Item.embedding.l2_distance(question_vector)).label('distance')\n",
    "    ).order_by('distance').limit(5).all()\n",
    ")\n",
    "\n",
    "# for item, distance in results:\n",
    "#     pprint.pp(item.text)\n",
    "#     pprint.pp(distance)"
   ],
   "id": "d6931517756aa06a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Our architecture is based on microservices. Each service is independent and '\n",
      " 'communicates with others via REST APIs. Services are deployed in Docker '\n",
      " 'containers and managed via Kubernetes.')\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T22:29:50.506661Z",
     "start_time": "2024-11-24T22:29:45.277802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Based on the vector search (similarity) results, ask llama to generate a response.\n",
    "# For better implementation check this: https://python.langchain.com/docs/integrations/chat/llama2_chat/\n",
    "\n",
    "from ollama import ChatResponse\n",
    "\n",
    "internal_question = f\"\"\"\n",
    "Based on the following retrieved documents:\n",
    "---\n",
    "1. {results[0][0].text}\n",
    "---\n",
    "2. {results[1][0].text}\n",
    "---\n",
    "3. {results[2][0].text}\n",
    "---\n",
    "Answer the question: \"{question}\"\n",
    "\"\"\"\n",
    "\n",
    "response: ChatResponse = client.chat(model='llama3.2', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': internal_question,\n",
    "    },\n",
    "])\n",
    "\n",
    "pprint(response['message']['content'])\n",
    "\n",
    "# or access fields directly from the response object\n",
    "# print(response.message.content)"
   ],
   "id": "d65af2f1737e7d33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('According to the retrieved documents, services are deployed in Docker '\n",
      " 'containers and managed via Kubernetes.')\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
